<html>

<head>
    <script src="static/js/face-api.min.js"></script>
</head>

<body>

    <!-- style to centr video -->
    <video id="video" width="720" height="560" autoplay muted style="display: block; margin: 0 auto;"></video>
    <div id="log">Log</div>
    <div id="matchedLog">?</div>
    <div id="eyeCloseLog">?</div>
    <script>


        var log = document.getElementById("log");
        var matchedLog = document.getElementById("matchedLog");
        const video = document.getElementById("video");

        const MODLES = 'static/models';
        async function loadModels() {
            log.innerText = "Loading models...";
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODLES);
            await faceapi.nets.faceRecognitionNet.loadFromUri(MODLES);
            await faceapi.nets.faceLandmark68Net.loadFromUri(MODLES);
            log.innerText = "Models loaded";
        }




        var videoStream = null; // Store camera stream for release

        async function startCamera() {

            log.innerText = 'Requesting camera...';

            videoStream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: 320, height: 240 }
            });
            video.srcObject = videoStream;

            log.innerText = '‚úÖ Ready! Close eyes to mark';

        }








        function euclideanDistance(a, b) {
            return Math.sqrt(a.reduce((sum, v, i) => sum + Math.pow(v - b[i], 2), 0));
        }




        // ========== ANTI-SPOOFING CONFIG ==========
        const EAR_CLOSED_THRESHOLD = 0.22;   // EAR below this = eyes closed
        const EAR_OPEN_THRESHOLD = 0.26;     // EAR above this = eyes open (hysteresis)
        const REQUIRED_CLOSED_FRAMES = 3;    // Consecutive closed frames needed
        const MAX_FACE_SHIFT = 15;           // Max px face center can move per frame during blink
        const MIN_FACE_WIDTH = 101;          // Reject far-away faces
        const SAME_FACE_THRESHOLD = 0.4;     // Max descriptor distance for same face

        // ========== ANTI-SPOOFING STATE ==========
        let blinkState = 'WAITING_FOR_CLOSE'; // WAITING_FOR_CLOSE | EYES_CLOSED | BLINK_COMPLETE
        let closedFrameCount = 0;
        let lastFaceCenter = null;
        let lastFaceDescriptor = null;
        let faceStableDuringBlink = true;

        // ========== SAME FACE TRACKING ==========
        function isSameFace(currentDescriptor) {
            if (!lastFaceDescriptor) {
                lastFaceDescriptor = currentDescriptor;
                return true;
            }
            const distance = euclideanDistance(currentDescriptor, lastFaceDescriptor);
            if (distance < SAME_FACE_THRESHOLD) {
                lastFaceDescriptor = currentDescriptor;
                return true;
            } else {
                lastFaceDescriptor = currentDescriptor;
                resetBlinkState();
                return false;
            }
        }

        function resetBlinkState() {
            blinkState = 'WAITING_FOR_CLOSE';
            closedFrameCount = 0;
            faceStableDuringBlink = true;
        }

        // ========== EAR (Eye Aspect Ratio) ==========
        // Uses all 6 eye landmark points for scale-invariant measurement
        // EAR = (|p2-p6| + |p3-p5|) / (2 * |p1-p4|)
        function pointDist(a, b) {
            return Math.sqrt(Math.pow(a.x - b.x, 2) + Math.pow(a.y - b.y, 2));
        }

        function computeEAR(eyePoints) {
            // eyePoints: 6 points [p1..p6] from face-api landmark
            const vertical1 = pointDist(eyePoints[1], eyePoints[5]);
            const vertical2 = pointDist(eyePoints[2], eyePoints[4]);
            const horizontal = pointDist(eyePoints[0], eyePoints[3]);
            if (horizontal === 0) return 1; // Avoid division by zero
            return (vertical1 + vertical2) / (2 * horizontal);
        }

        // ========== FACE STABILITY CHECK ==========
        function checkFaceStability(faceBox) {
            const cx = faceBox.x + faceBox.width / 2;
            const cy = faceBox.y + faceBox.height / 2;

            if (lastFaceCenter) {
                const dx = Math.abs(cx - lastFaceCenter.x);
                const dy = Math.abs(cy - lastFaceCenter.y);
                if (dx > MAX_FACE_SHIFT || dy > MAX_FACE_SHIFT) {
                    faceStableDuringBlink = false;
                }
            }
            lastFaceCenter = { x: cx, y: cy };
        }

        // ========== BLINK CYCLE STATE MACHINE ==========
        // Requires full cycle: OPEN ‚Üí CLOSED (N frames) ‚Üí OPEN
        function detectBlink(landmarks, descriptor, faceBox) {
            // Same face check
            if (!isSameFace(descriptor)) {
                return false;
            }

            // Compute EAR for both eyes
            const leftEye = landmarks.getLeftEye();
            const rightEye = landmarks.getRightEye();
            const leftEAR = computeEAR(leftEye);
            const rightEAR = computeEAR(rightEye);
            const avgEAR = (leftEAR + rightEAR) / 2;

            // Track face position stability
            checkFaceStability(faceBox);

            // Debug display
            matchedLog.innerText = 'EAR:' + avgEAR.toFixed(3)
                + ' state:' + blinkState
                + ' closed:' + closedFrameCount
                + ' stable:' + (faceStableDuringBlink ? '‚úì' : '‚úó')
                + ' face:' + faceBox.width.toFixed(0) + 'px';

            // State machine
            switch (blinkState) {
                case 'WAITING_FOR_CLOSE':
                    if (avgEAR < EAR_CLOSED_THRESHOLD) {
                        closedFrameCount++;
                        if (closedFrameCount >= REQUIRED_CLOSED_FRAMES) {
                            blinkState = 'EYES_CLOSED';
                            faceStableDuringBlink = true; // Start tracking stability from here
                        }
                    } else {
                        closedFrameCount = 0;
                        faceStableDuringBlink = true;
                    }
                    return false;

                case 'EYES_CLOSED':
                    if (avgEAR > EAR_OPEN_THRESHOLD) {
                        // Eyes reopened ‚Äî check if face was stable during blink
                        if (faceStableDuringBlink) {
                            blinkState = 'BLINK_COMPLETE';
                            return true; // Real blink detected!
                        } else {
                            // Face moved too much ‚Äî likely a photo being shifted
                            log.innerText = '‚ö†Ô∏è Spoof rejected (face moved)';
                            resetBlinkState();
                            return false;
                        }
                    }
                    // Still closed ‚Äî keep tracking stability
                    return false;

                case 'BLINK_COMPLETE':
                    // Already triggered, reset for next blink
                    resetBlinkState();
                    return false;
            }
            return false;
        }

        // ========== DETECT LOOP ==========
        async function detectLoop() {
            const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptor();
            if (!detections) {
                log.innerText = "No Face detected";
                resetBlinkState();
                lastFaceCenter = null;
            } else {
                const faceBox = detections.detection.box;

                if (faceBox.width < MIN_FACE_WIDTH) {
                    log.innerText = "‚ö†Ô∏è Too far! Face:" + faceBox.width.toFixed(0) + "px";
                    matchedLog.innerText = "Move closer (need " + MIN_FACE_WIDTH + "px, got " + faceBox.width.toFixed(0) + "px)";
                    resetBlinkState();
                } else {
                    log.innerText = "Face detected (size:" + faceBox.width.toFixed(0) + "px)";
                    const blinked = detectBlink(detections.landmarks, Array.from(detections.descriptor), faceBox);

                    if (blinked) {
                        log.innerText = 'üòë Blink Detected!';
                        eyeCloseLog.innerText = 'üòë Blink Detected!';
                    }
                }
            }
            requestAnimationFrame(detectLoop);

        }


        async function main() {
            await loadModels();
            await startCamera();
            video.onloadeddata = function () {
                detectLoop()
            }
        }
        main();
    </script>
</body>

</html>